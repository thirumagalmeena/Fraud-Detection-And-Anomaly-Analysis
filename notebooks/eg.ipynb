{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06_neural_network_fraud_detection.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                             average_precision_score, f1_score, precision_score, recall_score)\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=== Fraud Detection: Neural Network Classifier ===\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# STEP 1: Load and Prepare Data\n",
    "print(\"\\n1. Loading and preparing data...\")\n",
    "\n",
    "# Load the cleaned data\n",
    "df = pd.read_csv('data/processed/cc_cleaned.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Select only numerical features\n",
    "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "X = X[numerical_features]\n",
    "\n",
    "print(f\"Using {len(numerical_features)} numerical features\")\n",
    "print(f\"Class distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# STEP 2: Data Scaling (Critical for Neural Networks)\n",
    "print(\"\\n2. Scaling data for neural network...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"‚úì Data scaled using StandardScaler\")\n",
    "print(f\"Scaled data shape: {X_scaled.shape}\")\n",
    "\n",
    "# STEP 3: Train-Validation-Test Split\n",
    "print(\"\\n3. Creating train-validation-test split...\")\n",
    "\n",
    "# First split: train+validation vs test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Second split: train vs validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Training fraud rate: {y_train.mean():.4f}\")\n",
    "print(f\"Validation fraud rate: {y_val.mean():.4f}\")\n",
    "print(f\"Test fraud rate: {y_test.mean():.4f}\")\n",
    "\n",
    "# STEP 4: Handle Class Imbalance\n",
    "print(\"\\n4. Handling class imbalance...\")\n",
    "\n",
    "# Calculate class weights for the loss function\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weight_dict}\")\n",
    "print(f\"Fraud weight is {class_weight_dict[1]/class_weight_dict[0]:.1f}x higher than legitimate weight\")\n",
    "\n",
    "# STEP 5: Build Neural Network Architecture\n",
    "print(\"\\n5. Building neural network architecture...\")\n",
    "\n",
    "# Clear any previous models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    # Input layer\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    \n",
    "    # First hidden layer with dropout\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Second hidden layer\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Third hidden layer\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # Output layer (sigmoid for binary classification)\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='pr_auc', curve='PR')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"‚úì Neural Network architecture built\")\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# STEP 6: Set up Callbacks\n",
    "print(\"\\n6. Setting up training callbacks...\")\n",
    "\n",
    "# Define callbacks\n",
    "callbacks_list = [\n",
    "    # Early stopping to prevent overfitting\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_pr_auc',  # Monitor PR-AUC (better for imbalanced data)\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Model checkpoint to save best model\n",
    "    callbacks.ModelCheckpoint(\n",
    "        'models/neural_network_best.h5',\n",
    "        monitor='val_pr_auc',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úì Callbacks configured (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)\")\n",
    "\n",
    "# STEP 7: Train the Neural Network\n",
    "print(\"\\n7. Training neural network...\")\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "print(f\"Training parameters:\")\n",
    "print(f\"‚Ä¢ Batch size: {batch_size}\")\n",
    "print(f\"‚Ä¢ Max epochs: {epochs}\")\n",
    "print(f\"‚Ä¢ Class weights applied: {class_weight_dict}\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úì Neural network training completed\")\n",
    "\n",
    "# STEP 8: Load Best Model\n",
    "print(\"\\n8. Loading best model from training...\")\n",
    "\n",
    "# Load the best saved model\n",
    "best_model = keras.models.load_model('models/neural_network_best.h5')\n",
    "print(\"‚úì Best model loaded\")\n",
    "\n",
    "# STEP 9: Make Predictions\n",
    "print(\"\\n9. Making predictions...\")\n",
    "\n",
    "# Get probability scores\n",
    "y_pred_proba = best_model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# Predict with default threshold (0.5)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"‚úì Predictions generated\")\n",
    "\n",
    "# STEP 10: Evaluate Model Performance\n",
    "print(\"\\n10. Evaluating model performance...\")\n",
    "\n",
    "# Basic metrics with default threshold\n",
    "print(\"\\nPerformance with default threshold (0.5):\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "print(f\"Avg Precision: {avg_precision:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                    index=['Actual Legit', 'Actual Fraud'], \n",
    "                    columns=['Predicted Legit', 'Predicted Fraud'])\n",
    "print(cm_df)\n",
    "\n",
    "# STEP 11: Threshold Tuning for Fraud Detection\n",
    "print(\"\\n11. Threshold tuning analysis...\")\n",
    "\n",
    "# Try different thresholds\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= threshold).astype(int)\n",
    "    precision_t = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    recall_t = recall_score(y_test, y_pred_thresh)\n",
    "    f1_t = f1_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    \n",
    "    # Calculate business metrics\n",
    "    cm_thresh = confusion_matrix(y_test, y_pred_thresh)\n",
    "    false_positives = cm_thresh[0, 1]\n",
    "    true_positives = cm_thresh[1, 1]\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'precision': precision_t,\n",
    "        'recall': recall_t,\n",
    "        'f1_score': f1_t,\n",
    "        'false_positives': false_positives,\n",
    "        'true_positives': true_positives,\n",
    "        'alerts_per_fraud': false_positives / true_positives if true_positives > 0 else np.inf\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nPerformance across different thresholds:\")\n",
    "print(results_df[['threshold', 'precision', 'recall', 'f1_score', 'alerts_per_fraud']].round(4))\n",
    "\n",
    "# Find optimal threshold based on F1-score\n",
    "optimal_idx = results_df['f1_score'].idxmax()\n",
    "optimal_threshold = results_df.loc[optimal_idx, 'threshold']\n",
    "optimal_f1 = results_df.loc[optimal_idx, 'f1_score']\n",
    "\n",
    "print(f\"\\nOptimal threshold: {optimal_threshold:.2f} (F1-score: {optimal_f1:.4f})\")\n",
    "print(f\"At optimal threshold: Precision = {results_df.loc[optimal_idx, 'precision']:.1%}, \"\n",
    "      f\"Recall = {results_df.loc[optimal_idx, 'recall']:.1%}\")\n",
    "\n",
    "# STEP 12: Training History Visualization\n",
    "print(\"\\n12. Creating training visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "axes[0,0].plot(history.history['loss'], label='Training Loss')\n",
    "axes[0,0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[0,0].set_xlabel('Epoch')\n",
    "axes[0,0].set_ylabel('Loss')\n",
    "axes[0,0].set_title('Training and Validation Loss')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy curves\n",
    "axes[0,1].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[0,1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0,1].set_xlabel('Epoch')\n",
    "axes[0,1].set_ylabel('Accuracy')\n",
    "axes[0,1].set_title('Training and Validation Accuracy')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Precision-Recall curves\n",
    "axes[0,2].plot(history.history['precision'], label='Training Precision')\n",
    "axes[0,2].plot(history.history['val_precision'], label='Validation Precision')\n",
    "axes[0,2].plot(history.history['recall'], label='Training Recall')\n",
    "axes[0,2].plot(history.history['val_recall'], label='Validation Recall')\n",
    "axes[0,2].set_xlabel('Epoch')\n",
    "axes[0,2].set_ylabel('Score')\n",
    "axes[0,2].set_title('Training and Validation Precision/Recall')\n",
    "axes[0,2].legend()\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "axes[1,0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "axes[1,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[1,0].set_xlabel('False Positive Rate')\n",
    "axes[1,0].set_ylabel('True Positive Rate (Recall)')\n",
    "axes[1,0].set_title('ROC Curve - Neural Network')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Precision-Recall Curve\n",
    "precision_vals, recall_vals, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
    "axes[1,1].plot(recall_vals, precision_vals, color='blue', lw=2, \n",
    "               label=f'PR curve (AP = {avg_precision:.4f})')\n",
    "axes[1,1].set_xlabel('Recall')\n",
    "axes[1,1].set_ylabel('Precision')\n",
    "axes[1,1].set_title('Precision-Recall Curve - Neural Network')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Threshold Analysis\n",
    "axes[1,2].plot(results_df['threshold'], results_df['precision'], 'o-', label='Precision')\n",
    "axes[1,2].plot(results_df['threshold'], results_df['recall'], 'o-', label='Recall')\n",
    "axes[1,2].plot(results_df['threshold'], results_df['f1_score'], 'o-', label='F1-Score')\n",
    "axes[1,2].axvline(optimal_threshold, color='red', linestyle='--', \n",
    "                  label=f'Optimal threshold: {optimal_threshold:.2f}')\n",
    "axes[1,2].set_xlabel('Threshold')\n",
    "axes[1,2].set_ylabel('Score')\n",
    "axes[1,2].set_title('Threshold Tuning Analysis')\n",
    "axes[1,2].legend()\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# STEP 13: Compare with Previous Models\n",
    "print(\"\\n13. Comparison with previous models...\")\n",
    "\n",
    "try:\n",
    "    # Load previous model results\n",
    "    lr_performance = pd.read_csv('reports/logistic_regression_performance.csv').iloc[0]\n",
    "    dt_performance = pd.read_csv('reports/decision_tree_performance.csv').iloc[0]\n",
    "    rf_performance = pd.read_csv('reports/random_forest_performance.csv').iloc[0]\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': ['Recall', 'Precision', 'F1-Score', 'ROC-AUC', 'Avg Precision'],\n",
    "        'Neural Network': [recall, precision, f1, roc_auc, avg_precision],\n",
    "        'Random Forest': [rf_performance['recall'], rf_performance['precision'], \n",
    "                         rf_performance['f1_score'], rf_performance['roc_auc'], \n",
    "                         rf_performance['avg_precision']],\n",
    "        'Decision Tree': [dt_performance['recall'], dt_performance['precision'], \n",
    "                         dt_performance['f1_score'], dt_performance['roc_auc'], \n",
    "                         dt_performance['avg_precision']],\n",
    "        'Logistic Regression': [lr_performance['recall'], lr_performance['precision'], \n",
    "                               lr_performance['f1_score'], lr_performance['roc_auc'], \n",
    "                               lr_performance['avg_precision']]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nModel Comparison:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(comparison.round(4))\n",
    "    \n",
    "    # Visual comparison\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    metrics = ['Recall', 'Precision', 'F1-Score', 'ROC-AUC']\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.2\n",
    "    \n",
    "    ax.bar(x - width*1.5, comparison.loc[:3, 'Neural Network'], width, label='Neural Network')\n",
    "    ax.bar(x - width*0.5, comparison.loc[:3, 'Random Forest'], width, label='Random Forest')\n",
    "    ax.bar(x + width*0.5, comparison.loc[:3, 'Decision Tree'], width, label='Decision Tree')\n",
    "    ax.bar(x + width*1.5, comparison.loc[:3, 'Logistic Regression'], width, label='Logistic Regression')\n",
    "    \n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Model Comparison: Neural Network vs All Previous Models')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ö† Previous model results not found: {e}\")\n",
    "\n",
    "# STEP 14: Save Model and Results\n",
    "print(\"\\n14. Saving model and results...\")\n",
    "\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('reports/figures', exist_ok=True)\n",
    "\n",
    "# Save the full model\n",
    "best_model.save('models/neural_network_final.h5')\n",
    "print(\"‚úì Model saved: models/neural_network_final.h5\")\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'models/neural_network_scaler.pkl')\n",
    "print(\"‚úì Scaler saved: models/neural_network_scaler.pkl\")\n",
    "\n",
    "# Save performance results\n",
    "performance_report = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'roc_auc': roc_auc,\n",
    "    'avg_precision': avg_precision,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'n_epochs_trained': len(history.history['loss']),\n",
    "    'best_val_pr_auc': max(history.history['val_pr_auc']),\n",
    "    'architecture': '64-32-16-1',\n",
    "    'class_weight_fraud': class_weight_dict[1]\n",
    "}\n",
    "\n",
    "performance_df = pd.DataFrame([performance_report])\n",
    "performance_df.to_csv('reports/neural_network_performance.csv', index=False)\n",
    "print(\"‚úì Performance report saved: reports/neural_network_performance.csv\")\n",
    "\n",
    "# Save threshold analysis\n",
    "results_df.to_csv('reports/neural_network_threshold_analysis.csv', index=False)\n",
    "\n",
    "# STEP 15: Final Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL SUMMARY - NEURAL NETWORK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
    "print(f\"‚Ä¢ Recall (Frauds Caught): {recall:.1%}\")\n",
    "print(f\"‚Ä¢ Precision (Accuracy of Fraud Alerts): {precision:.1%}\")\n",
    "print(f\"‚Ä¢ F1-Score: {f1:.4f}\")\n",
    "print(f\"‚Ä¢ ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ BUSINESS IMPACT:\")\n",
    "frauds_caught = cm[1, 1]  # True Positives\n",
    "frauds_missed = cm[1, 0]  # False Negatives\n",
    "false_alarms = cm[0, 1]   # False Positives\n",
    "\n",
    "print(f\"‚Ä¢ Frauds detected: {frauds_caught}/{frauds_caught + frauds_missed} ({recall:.1%})\")\n",
    "print(f\"‚Ä¢ False alarms: {false_alarms} legitimate transactions flagged\")\n",
    "print(f\"‚Ä¢ Optimal threshold: {optimal_threshold:.2f}\")\n",
    "\n",
    "print(f\"\\nüß† NEURAL NETWORK CHARACTERISTICS:\")\n",
    "print(f\"‚Ä¢ Architecture: 64-32-16-1 (3 hidden layers)\")\n",
    "print(f\"‚Ä¢ Training epochs: {len(history.history['loss'])}\")\n",
    "print(f\"‚Ä¢ Best validation PR-AUC: {max(history.history['val_pr_auc']):.4f}\")\n",
    "print(f\"‚Ä¢ Class weight for fraud: {class_weight_dict[1]:.1f}x\")\n",
    "\n",
    "print(f\"\\nüîç KEY INSIGHTS:\")\n",
    "print(f\"‚Ä¢ Deep learning can capture complex fraud patterns\")\n",
    "print(f\"‚Ä¢ Neural networks excel at learning feature interactions\")\n",
    "print(f\"‚Ä¢ Regularization techniques prevent overfitting on rare fraud cases\")\n",
    "\n",
    "print(f\"\\nüèÜ COMPARISON HIGHLIGHTS:\")\n",
    "print(f\"‚Ä¢ Expected to match or exceed Random Forest performance\")\n",
    "print(f\"‚Ä¢ Can learn non-linear patterns that tree-based models miss\")\n",
    "print(f\"‚Ä¢ More parameters but better feature representation\")\n",
    "\n",
    "print(f\"\\n‚úÖ NEXT STEPS:\")\n",
    "print(\"1. Consider ensemble of Neural Network + Random Forest\")\n",
    "print(\"2. Implement real-time scoring with TensorFlow Serving\")\n",
    "print(\"3. Monitor model drift and retrain periodically\")\n",
    "print(\"4. Explore deep learning architectures (Autoencoders, LSTMs for sequences)\")\n",
    "\n",
    "print(f\"\\n‚úì Neural Network implementation completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
